<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->

<configuration>
<!-- special parameters for avatarnode -->
  <property>
	<name>fs.default.name0</name>
	<value>hdfs://172.16.40.234:9000</value>
  </property>

  <property>
	<name>fs.default.name1</name>
	<value>hdfs://0.0.0.0:9000</value>
  </property>

<!-- special parameters for avatarnode -->

<property>
	<name>fs.default.name</name>
	<value>hdfs://172.16.40.234:9000</value>
</property>

<property>
	<name>io.file.buffer.size</name>
	<!--<value>131072</value>-->
        <value>4096</value>
</property>

<property>
	<name>hadoop.tmp.dir</name>
	<!--<value>/smp/tmp</value>-->
        <value>/home/hadoop/hadoop-tmp/avatar-hadoop/tmp</value>
</property>

<property>
	<name>fs.trash.interval</name>
	<!--<value>1440</value>-->
        <value>0</value>
</property>

<property>
  <name>webinterface.private.actions</name>
  <value>true</value>
  <description> If set to true, the web interfaces of JT and NN may contain 
                actions, such as kill job, delete file, etc., that should 
                not be exposed to public. Enable this option if the interfaces 
                are only reachable by those who have the right authorization.
  </description>
</property>

<property>
        <name>ipc.client.connect.max.retries</name>
        <value>10</value>
</property>

<property>
  <name>fs.checkpoint.dir</name>
  <value>${hadoop.tmp.dir}/dfs/namesecondary</value>
  <description>Determines where on the local filesystem the DFS secondary
      name node should store the temporary images to merge.
      If this is a comma-delimited list of directories then the image is
      replicated in all of the directories for redundancy.
  </description>
</property>

<property>
  <name>fs.checkpoint.edits.dir</name>
  <value>${fs.checkpoint.dir}</value>
  <description>Determines where on the local filesystem the DFS secondary
      name node should store the temporary edits to merge.
      If this is a comma-delimited list of directoires then teh edits is
      replicated in all of the directoires for redundancy.
      Default value is same as fs.checkpoint.dir
  </description>
</property>

<property>
  <name>fs.checkpoint.period</name>
  <value>3600</value>
  <description>The number of seconds between two periodic checkpoints.
  </description>
</property>

<property>
  <name>fs.checkpoint.size</name>
  <value>67108864</value>
  <description>The size of the current edit log (in bytes) that triggers
       a periodic checkpoint even if the fs.checkpoint.period hasn't expired.
  </description>
</property>

 <property>
       <name>hadoop.install.dir</name>
       <value>/dinglicom/hadoop/lib/</value>
</property>

<property>
 <name>hadoop.usrjar.ip</name>
   <value>172.16.4.100:8888</value>
</property>

<property>
   <name>hadoop.database.name</name>
         <value>cdr</value>
</property>

<property>
   <name>dfs.hadoop.namenode</name>
   <value>hdfs://172.16.40.234:9000</value>
</property>

<property>
   <name>dfs.hadoop.conf</name>
         <value>/dinglicom/hadoop/conf</value>
          </property>

<property>
   <name>init.properties.url</name>
   <value>/dinglicom/hadoop/conf/init.properties</value>
</property>

</configuration>

